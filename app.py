import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import json
import requests
import os
import common
import config
from youtube_search import get_youtube_search_links

st.set_page_config(
    page_title="Urban Server Analytics",
    page_icon="üìä",
    layout="wide"
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
SCHEMA_NAME = config.schema_name
API_BASE_URL = config.URL.rstrip('/')  # –£–±–∏—Ä–∞–µ–º trailing slash, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å

def send_rest(endpoint):
    """
    –û—Ç–ø—Ä–∞–≤–∫–∞ REST –∑–∞–ø—Ä–æ—Å–∞ –∫ API
    """
    try:
        response = requests.get(f"{API_BASE_URL}/{endpoint}")
        return response.text, response.ok, response.status_code
    except Exception as e:
        return str(e), False, 500

@st.cache_data(ttl=3600)  # –ö—ç—à–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ 1 —á–∞—Å
def load_data():
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    """
    try:
        ans, is_ok, status_code = send_rest(f'v2/select/{SCHEMA_NAME}/nsi_list?column_order=id')
        if not is_ok:
            st.error('–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î')
            st.warning(f"URL –∑–∞–ø—Ä–æ—Å–∞: {API_BASE_URL}/v2/select/{SCHEMA_NAME}/nsi_list?column_order=id")
            st.warning(f"HTTP-–∫–æ–¥ –æ—Ç–≤–µ—Ç–∞: {status_code}")
            st.warning(f"–û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞: {ans}")
            return None
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º JSON –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
        data = json.loads(ans)
        
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(data)
        
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥—É–±–ª–∏–∫–∞—Ç–∞—Ö
        st.write(f"–í—Å–µ–≥–æ –≤–∏–¥–µ–æ: {len(df)}")
        
        try:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DataFrame —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            df_unique = df.drop_duplicates(subset=['id_site'], keep='last')
            
            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
            df_unique = df_unique.rename(columns={
                'video_published_at': 'published_at',
                'id_site': 'video_id',
                'sh_name': 'title',
                'likes': 'likes_count',
                'dislikes': 'dislikes_count',
                'comments_count': 'comments_count',
                'views_count': 'views_count',
                'sentiment': 'sentiment',
                'value': 'sentiment_value',
                'channel_title': 'channel_title',
                'video_duration': 'duration'
            })
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—ã
            df_unique['published_at'] = pd.to_datetime(df_unique['published_at'], errors='coerce')
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ
            def parse_duration(duration):
                if pd.isna(duration):
                    return "00:00"
                try:
                    # –£–±–∏—Ä–∞–µ–º 'PT' –∏–∑ –Ω–∞—á–∞–ª–∞
                    duration = duration.replace('PT', '')
                    minutes = 0
                    seconds = 0
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–∏–Ω—É—Ç—ã
                    if 'M' in duration:
                        minutes_part = duration.split('M')[0]
                        minutes = int(minutes_part)
                        duration = duration.split('M')[1]
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–∫—É–Ω–¥—ã
                    if 'S' in duration:
                        seconds_part = duration.split('S')[0]
                        seconds = int(seconds_part)
                    
                    return f"{minutes:02d}:{seconds:02d}"
                except:
                    return "00:00"
            
            df_unique['duration'] = df_unique['duration'].apply(parse_duration)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            numeric_columns = ['views_count', 'likes_count', 'dislikes_count', 'comments_count']
            for col in numeric_columns:
                df_unique[col] = pd.to_numeric(df_unique[col], errors='coerce').fillna(0)
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –¥–∞—Ç–∞–º–∏
            df_unique = df_unique.dropna(subset=['published_at'])
            
            return df_unique
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
            st.error(f"–¢–∏–ø –æ—à–∏–±–∫–∏: {type(e)}")
            import traceback
            st.error(f"Traceback: {traceback.format_exc()}")
            return None
            
    except Exception as e:
        st.error(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}')
        st.error(f'–¢–∏–ø –æ—à–∏–±–∫–∏: {type(e)}')
        import traceback
        st.error(f'Traceback: {traceback.format_exc()}')
        return None

def create_sentiment_distribution(df):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
    """
    sentiment_counts = df['sentiment'].value_counts()
    
    fig = px.pie(
        values=sentiment_counts.values,
        names=sentiment_counts.index,
        title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –≤ –≤–∏–¥–µ–æ',
        color_discrete_sequence=px.colors.qualitative.Set3
    )
    
    fig.update_traces(textposition='inside', textinfo='percent+label')
    return fig

def create_engagement_metrics(df):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –º–µ—Ç—Ä–∏–∫ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏
    """
    engagement_data = df.groupby('video_id').agg({
        'views_count': 'first',
        'likes_count': 'first',
        'dislikes_count': 'first',
        'comments_count': 'first'
    }).reset_index()
    
    fig = go.Figure()
    
    metrics = {
        'views_count': '–ü—Ä–æ—Å–º–æ—Ç—Ä—ã',
        'likes_count': '–õ–∞–π–∫–∏',
        'dislikes_count': '–î–∏–∑–ª–∞–π–∫–∏',
        'comments_count': '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏'
    }
    
    for col, name in metrics.items():
        fig.add_trace(go.Bar(
            name=name,
            y=[engagement_data[col].mean()],
            x=[name],
            text=[f"{engagement_data[col].mean():,.0f}"],
            textposition='auto',
        ))
    
    fig.update_layout(
        title='–°—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏',
        barmode='group',
        showlegend=False,
        yaxis_title='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'
    )
    
    return fig

def create_views_timeline(df):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
    """
    try:
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é DataFrame –¥–ª—è —Ä–∞–±–æ—Ç—ã
        df_timeline = df.copy()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ published_at
        if 'published_at' not in df_timeline.columns:
            st.error("–ö–æ–ª–æ–Ω–∫–∞ published_at –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
        if df_timeline['published_at'].duplicated().any():
            st.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –¥–∞—Ç–∞—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–∏")
            # –î–æ–±–∞–≤–ª—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫ –¥—É–±–ª–∏–∫–∞—Ç–∞–º
            df_timeline['published_at'] = df_timeline.apply(
                lambda row: f"{row['published_at']}_{row['video_id']}", 
                axis=1
            )
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        df_timeline = df_timeline.sort_values('published_at')
        
        fig = px.line(
            df_timeline,
            x='published_at',
            y='views_count',
            title='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏',
            labels={'views_count': '–ü—Ä–æ—Å–º–æ—Ç—Ä—ã', 'published_at': '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏'}
        )
        
        return fig
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞: {str(e)}")
        return None

def create_top_channels(df):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ —Ç–æ–ø –∫–∞–Ω–∞–ª–æ–≤
    """
    channel_stats = df.groupby('channel_title').agg({
        'video_id': 'count',
        'views_count': 'sum',
        'likes_count': 'sum'
    }).reset_index()
    
    channel_stats = channel_stats.sort_values('views_count', ascending=False).head(10)
    
    fig = px.bar(
        channel_stats,
        x='channel_title',
        y='views_count',
        title='–¢–æ–ø-10 –∫–∞–Ω–∞–ª–æ–≤ –ø–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞–º',
        labels={'views_count': '–ü—Ä–æ—Å–º–æ—Ç—Ä—ã', 'channel_title': '–ö–∞–Ω–∞–ª'},
        color='likes_count',
        color_continuous_scale='Viridis'
    )
    
    fig.update_layout(xaxis_tickangle=-45)
    return fig

def main():
    st.title("üìä Urban Server Analytics")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = load_data()
    if df is None:
        st.stop()
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
    st.sidebar.header("–§–∏–ª—å—Ç—Ä—ã")
    
    # –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ
    try:
        min_date = df['published_at'].min().date()
        max_date = df['published_at'].max().date()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        st.sidebar.write(f"**–î–æ—Å—Ç—É–ø–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç:**")
        st.sidebar.write(f"‚Ä¢ –û—Ç: {min_date.strftime('%d.%m.%Y')}")
        st.sidebar.write(f"‚Ä¢ –î–æ: {max_date.strftime('%d.%m.%Y')}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã–±–æ—Ä –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞—Ç
        date_filter_type = st.sidebar.radio(
            "–¢–∏–ø —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ –¥–∞—Ç–µ",
            ["–ü—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥", "–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥"]
        )
        
        if date_filter_type == "–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥":
            relative_period = st.sidebar.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–∏–æ–¥",
                ["–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 90 –¥–Ω–µ–π", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 180 –¥–Ω–µ–π", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 365 –¥–Ω–µ–π"]
            )
            
            # –í—ã—á–∏—Å–ª—è–µ–º –¥–∞—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
            end_date = max_date  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É –∏–∑ –¥–∞–Ω–Ω—ã—Ö
            if relative_period == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π":
                start_date = end_date - pd.Timedelta(days=7)
            elif relative_period == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π":
                start_date = end_date - pd.Timedelta(days=30)
            elif relative_period == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 90 –¥–Ω–µ–π":
                start_date = end_date - pd.Timedelta(days=90)
            elif relative_period == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 180 –¥–Ω–µ–π":
                start_date = end_date - pd.Timedelta(days=180)
            else:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 365 –¥–Ω–µ–π
                start_date = end_date - pd.Timedelta(days=365)
                
            date_range = (start_date, end_date)
        else:
            date_range = st.sidebar.date_input(
                "–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–∏–æ–¥",
                value=(min_date, max_date),
                min_value=min_date,
                max_value=max_date
            )
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞—Ç: {str(e)}")
        min_date = max_date = datetime.now().date()
        date_range = (min_date, max_date)
    
    # –§–∏–ª—å—Ç—Ä –ø–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—é
    sentiments = df['sentiment'].dropna().unique()
    if len(sentiments) > 0:
        selected_sentiments = st.sidebar.multiselect(
            "–í—ã–±–µ—Ä–∏—Ç–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è",
            options=sentiments,
            default=sentiments
        )
    else:
        selected_sentiments = []
        st.sidebar.write("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π")
    
    # –§–∏–ª—å—Ç—Ä –ø–æ –ø–æ–∏—Å–∫–æ–≤—ã–º –æ–±—Ä–∞–∑–∞–º
    st.sidebar.subheader("–ü–æ–∏—Å–∫–æ–≤—ã–µ –æ–±—Ä–∞–∑—ã")
    search_query = st.sidebar.text_input("–ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏—é")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ YouTube
    if st.sidebar.button("–ù–æ–≤—ã–π –ø–æ–∏—Å–∫ –≤ YouTube"):
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
            videos = get_youtube_search_links(search_query, days_ago=30)
            
            if videos:
                st.sidebar.success(f"–ù–∞–π–¥–µ–Ω–æ {len(videos)} –≤–∏–¥–µ–æ")
                # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
                df = load_data()
            else:
                st.sidebar.warning("–í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        except Exception as e:
            st.sidebar.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {str(e)}")
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
    try:
        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        date_mask = (df['published_at'].dt.date >= date_range[0]) & (df['published_at'].dt.date <= date_range[1])
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        filtered_df = df[date_mask]
        
        if len(selected_sentiments) > 0:
            sentiment_mask = filtered_df['sentiment'].isin(selected_sentiments)
            filtered_df = filtered_df[sentiment_mask]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π —Ñ–∏–ª—å—Ç—Ä
        if search_query:
            search_mask = (
                filtered_df['title'].str.contains(search_query, case=False, na=False) |
                filtered_df['description'].str.contains(search_query, case=False, na=False)
            )
            filtered_df = filtered_df[search_mask]
            
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–∞—Ö
        st.sidebar.write("---")
        st.sidebar.write("**–ü—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã:**")
        st.sidebar.write(f"‚Ä¢ –ü–µ—Ä–∏–æ–¥: {date_range[0].strftime('%d.%m.%Y')} - {date_range[1].strftime('%d.%m.%Y')}")
        if len(selected_sentiments) > 0:
            st.sidebar.write(f"‚Ä¢ –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏—è: {', '.join(selected_sentiments)}")
        if search_query:
            st.sidebar.write(f"‚Ä¢ –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: {search_query}")
        
        st.sidebar.write(f"**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:**")
        st.sidebar.write(f"‚Ä¢ –ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ: {len(filtered_df)} –∏–∑ {len(df)}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö
        if len(filtered_df) == 0:
            st.warning("–ù–µ—Ç –≤–∏–¥–µ–æ, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        filtered_df = df
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("–í—Å–µ–≥–æ –≤–∏–¥–µ–æ", len(filtered_df))
    with col2:
        st.metric("–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤", f"{filtered_df['views_count'].sum():,}")
    with col3:
        st.metric("–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∞–π–∫–æ–≤", f"{filtered_df['likes_count'].sum():,}")
    with col4:
        st.metric("–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤", f"{filtered_df['comments_count'].sum():,}")
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    col1, col2 = st.columns(2)
    with col1:
        avg_views = filtered_df['views_count'].mean()
        st.metric("–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤", f"{avg_views:,.0f}")
    with col2:
        engagement_rate = (filtered_df['likes_count'].sum() + filtered_df['comments_count'].sum()) / filtered_df['views_count'].sum() * 100
        st.metric("–£—Ä–æ–≤–µ–Ω—å –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏", f"{engagement_rate:.2f}%")
    
    # –ì—Ä–∞—Ñ–∏–∫–∏
    st.plotly_chart(create_engagement_metrics(filtered_df), use_container_width=True)
    
    col1, col2 = st.columns(2)
    with col1:
        st.plotly_chart(create_sentiment_distribution(filtered_df), use_container_width=True)
    with col2:
        st.plotly_chart(create_top_channels(filtered_df), use_container_width=True)
    
    timeline_fig = create_views_timeline(filtered_df)
    if timeline_fig is not None:
        st.plotly_chart(timeline_fig, use_container_width=True)
    
    # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ–º—É –≤–∏–¥–µ–æ
    st.subheader("–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤–∏–¥–µ–æ")
    video_titles = filtered_df['title'].tolist()
    selected_video = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥–µ–æ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞",
        options=video_titles,
        index=0
    )
    
    if selected_video:
        video_data = filtered_df[filtered_df['title'] == selected_video].iloc[0]
        
        # –°–æ–∑–¥–∞–µ–º –≤–∫–ª–∞–¥–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        tab1, tab2 = st.tabs(["–û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è", "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏"])
        
        with tab1:
            col1, col2 = st.columns(2)
            with col1:
                st.write("**–û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:**")
                st.write(f"**–ù–∞–∑–≤–∞–Ω–∏–µ:** {video_data['title']}")
                st.write(f"**–ö–∞–Ω–∞–ª:** {video_data['channel_title']}")
                st.write(f"**–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏:** {video_data['published_at'].strftime('%d.%m.%Y %H:%M')}")
                st.write(f"**–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** {video_data['duration']}")
                st.write(f"**–ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ:** {video_data['sentiment']}")
                st.write(f"**–ó–Ω–∞—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è:** {video_data['sentiment_value']}")
                
            with col2:
                st.write("**–ú–µ—Ç—Ä–∏–∫–∏:**")
                st.write(f"**–ü—Ä–æ—Å–º–æ—Ç—Ä—ã:** {video_data['views_count']:,}")
                st.write(f"**–õ–∞–π–∫–∏:** {video_data['likes_count']:,}")
                st.write(f"**–î–∏–∑–ª–∞–π–∫–∏:** {video_data['dislikes_count']:,}")
                st.write(f"**–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏:** {video_data['comments_count']:,}")
                
                # –†–∞—Å—á–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
                like_ratio = video_data['likes_count'] / video_data['views_count'] * 100 if video_data['views_count'] > 0 else 0
                comment_ratio = video_data['comments_count'] / video_data['views_count'] * 100 if video_data['views_count'] > 0 else 0
                st.write(f"**–ü—Ä–æ—Ü–µ–Ω—Ç –ª–∞–π–∫–æ–≤:** {like_ratio:.2f}%")
                st.write(f"**–ü—Ä–æ—Ü–µ–Ω—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤:** {comment_ratio:.2f}%")
            
            # –°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ
            st.write(f"**–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ:** [{video_data['url']}]({video_data['url']})")
            
            # –û–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ
            if 'description' in video_data and video_data['description']:
                st.write("**–û–ø–∏—Å–∞–Ω–∏–µ –≤–∏–¥–µ–æ:**")
                st.write(video_data['description'])
        
        with tab2:
            st.write("**–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –≤–∏–¥–µ–æ**")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ
            try:
                comments_ans, is_ok, _ = send_rest(
                    f'v2/select/{SCHEMA_NAME}/nsi_comments?video_id={video_data["video_id"]}'
                )
                
                if is_ok:
                    comments_data = json.loads(comments_ans)
                    
                    if len(comments_data) > 0:
                        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
                        comments_df = pd.DataFrame(comments_data)
                        
                        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã
                        comments_df['published_at'] = pd.to_datetime(comments_df['published_at']).dt.strftime('%d.%m.%Y %H:%M')
                        
                        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏
                        comments_df = comments_df.rename(columns={
                            'sh_name': '–ê–≤—Ç–æ—Ä',
                            'text': '–¢–µ–∫—Å—Ç',
                            'likes': '–õ–∞–π–∫–∏',
                            'published_at': '–î–∞—Ç–∞'
                        })
                        
                        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
                        comments_df = comments_df.sort_values('–î–∞—Ç–∞', ascending=False)
                        
                        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                        st.dataframe(
                            comments_df[['–ê–≤—Ç–æ—Ä', '–¢–µ–∫—Å—Ç', '–õ–∞–π–∫–∏', '–î–∞—Ç–∞']],
                            use_container_width=True,
                            hide_index=True
                        )
                    else:
                        st.info("–ö —ç—Ç–æ–º—É –≤–∏–¥–µ–æ –ø–æ–∫–∞ –Ω–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤")
                else:
                    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏")
                    
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {str(e)}")
    
    # –¢–∞–±–ª–∏—Ü–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
    st.subheader("–î–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
    
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫
    column_names = {
        'title': '–ù–∞–∑–≤–∞–Ω–∏–µ',
        'url': '–°—Å—ã–ª–∫–∞',
        'views_count': '–ü—Ä–æ—Å–º–æ—Ç—Ä—ã',
        'likes_count': '–õ–∞–π–∫–∏',
        'dislikes_count': '–î–∏–∑–ª–∞–π–∫–∏',
        'comments_count': '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏',
        'sentiment': '–ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ',
        'sentiment_value': '–ó–Ω–∞—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è',
        'channel_title': '–ö–∞–Ω–∞–ª',
        'published_at': '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏',
        'duration': '–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'
    }
    
    display_columns = [
        'title', 'url', 'views_count', 
        'likes_count', 'dislikes_count', 'comments_count',
        'sentiment', 'sentiment_value', 'channel_title',
        'published_at', 'duration'
    ]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫
    display_columns = [col for col in display_columns if col in filtered_df.columns]
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞–º
    filtered_df = filtered_df.sort_values('views_count', ascending=False)
    
    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    display_df = filtered_df[display_columns].rename(columns=column_names)
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã
    display_df['–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏'] = display_df['–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏'].dt.strftime('%d.%m.%Y %H:%M')
    
    st.dataframe(
        display_df,
        use_container_width=True,
        hide_index=True
    )

if __name__ == '__main__':
    main() 